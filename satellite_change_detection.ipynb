{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f846424e",
   "metadata": {},
   "source": [
    "# Satellite Change Detection System\n",
    "\n",
    "This notebook demonstrates various techniques for detecting changes between before and after satellite images. It includes image differencing, thresholding, Change Vector Analysis (CVA), and deep learning approaches.\n",
    "\n",
    "**Features:**\n",
    "- Image preprocessing and alignment\n",
    "- Multiple change detection methods\n",
    "- Deep learning-based semantic change detection\n",
    "- Visualization and statistics\n",
    "- Export results as GeoTIFF or PNG\n",
    "\n",
    "Works seamlessly in Google Colab!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27e144f",
   "metadata": {},
   "source": [
    "## 1. Install Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279735e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# Install required packages\n",
    "packages = [\n",
    "    'opencv-python',\n",
    "    'scikit-image',\n",
    "    'rasterio',\n",
    "    'geopandas',\n",
    "    'tensorflow',\n",
    "    'torch',\n",
    "    'torchvision'\n",
    "]\n",
    "\n",
    "print(\"Installing required packages...\")\n",
    "for package in packages:\n",
    "    try:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", package])\n",
    "        print(f\"‚úì {package} installed\")\n",
    "    except:\n",
    "        print(f\"‚ö† {package} installation skipped (may already be installed)\")\n",
    "\n",
    "print(\"\\nAll packages installed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aaf0b24",
   "metadata": {},
   "source": [
    "## 2. Import Libraries and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f84ef3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from matplotlib.patches import Polygon\n",
    "from matplotlib.collections import PatchCollection\n",
    "import requests\n",
    "import os\n",
    "from urllib.request import urlretrieve\n",
    "from PIL import Image\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Check if running in Google Colab\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    IN_COLAB = True\n",
    "    print(\"Running in Google Colab\")\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "    print(\"Running locally\")\n",
    "\n",
    "# Set up matplotlib\n",
    "plt.style.use('default')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b505b30",
   "metadata": {},
   "source": [
    "## 3. Mount Google Drive (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa146a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "    drive.mount('/content/drive')\n",
    "    working_dir = '/content/drive/MyDrive/satellite_change_detection'\n",
    "    os.makedirs(working_dir, exist_ok=True)\n",
    "    print(f\"Google Drive mounted. Working directory: {working_dir}\")\n",
    "else:\n",
    "    working_dir = './satellite_data'\n",
    "    os.makedirs(working_dir, exist_ok=True)\n",
    "    print(f\"Working directory: {working_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcfcd5f",
   "metadata": {},
   "source": [
    "## 4. Download Sample Satellite Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2232fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sample_satellite_images(size=256):\n",
    "    \"\"\"\n",
    "    Create sample satellite images for demonstration\n",
    "    Simulates before and after satellite imagery\n",
    "    \"\"\"\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Create before image (base landscape)\n",
    "    before = np.zeros((size, size, 3), dtype=np.uint8)\n",
    "    \n",
    "    # Add background (green landscape)\n",
    "    before[:, :, 1] = np.random.randint(100, 150, (size, size))  # Green channel\n",
    "    before[:, :, 0] = np.random.randint(60, 100, (size, size))   # Blue channel\n",
    "    \n",
    "    # Add some natural features\n",
    "    cv2.circle(before, (50, 50), 20, (50, 100, 200), -1)  # Water body\n",
    "    cv2.circle(before, (200, 200), 30, (180, 180, 180), -1)  # Building\n",
    "    \n",
    "    # Create after image (with changes)\n",
    "    after = before.copy()\n",
    "    \n",
    "    # Simulate urban development (change)\n",
    "    cv2.rectangle(after, (100, 100), (180, 180), (150, 150, 150), -1)  # New development\n",
    "    cv2.circle(after, (50, 50), 20, (100, 150, 200), -1)  # Water expansion\n",
    "    \n",
    "    # Simulate forest loss (deforestation area)\n",
    "    after[150:200, 150:200, :] = [100, 100, 100]\n",
    "    \n",
    "    return before, after\n",
    "\n",
    "# Create sample images\n",
    "print(\"Creating sample satellite images...\")\n",
    "before_img, after_img = create_sample_satellite_images(size=256)\n",
    "\n",
    "print(\"Sample images created successfully!\")\n",
    "print(f\"Before image shape: {before_img.shape}\")\n",
    "print(f\"After image shape: {after_img.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7981255",
   "metadata": {},
   "source": [
    "## 5. Load and Visualize Before/After Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be17fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_images(before, after, title1=\"Before\", title2=\"After\"):\n",
    "    \"\"\"Visualize before and after images side by side\"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    \n",
    "    axes[0].imshow(cv2.cvtColor(before, cv2.COLOR_BGR2RGB))\n",
    "    axes[0].set_title(title1, fontsize=14, fontweight='bold')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    axes[1].imshow(cv2.cvtColor(after, cv2.COLOR_BGR2RGB))\n",
    "    axes[1].set_title(title2, fontsize=14, fontweight='bold')\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize the images\n",
    "visualize_images(before_img, after_img, \"Before Image\", \"After Image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef6264a",
   "metadata": {},
   "source": [
    "## 6. Preprocess Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3217b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_images(before, after, target_size=None):\n",
    "    \"\"\"\n",
    "    Preprocess satellite images:\n",
    "    - Resize to same dimensions\n",
    "    - Normalize pixel values\n",
    "    - Align images if needed\n",
    "    \"\"\"\n",
    "    # Resize if needed\n",
    "    if target_size:\n",
    "        before = cv2.resize(before, target_size)\n",
    "        after = cv2.resize(after, target_size)\n",
    "    \n",
    "    # Ensure same dimensions\n",
    "    if before.shape != after.shape:\n",
    "        h, w = min(before.shape[0], after.shape[0]), min(before.shape[1], after.shape[1])\n",
    "        before = cv2.resize(before, (w, h))\n",
    "        after = cv2.resize(after, (w, h))\n",
    "    \n",
    "    # Normalize (optional, helps with some methods)\n",
    "    before_normalized = before.astype(np.float32) / 255.0\n",
    "    after_normalized = after.astype(np.float32) / 255.0\n",
    "    \n",
    "    return before, after, before_normalized, after_normalized\n",
    "\n",
    "# Preprocess images\n",
    "before_proc, after_proc, before_norm, after_norm = preprocess_images(before_img, after_img)\n",
    "\n",
    "print(\"Preprocessing complete!\")\n",
    "print(f\"Processed image shape: {before_proc.shape}\")\n",
    "print(f\"Normalized value range: [{before_norm.min():.2f}, {before_norm.max():.2f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f7d1cd",
   "metadata": {},
   "source": [
    "## 7. Image Differencing Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9ca84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_differencing(before, after):\n",
    "    \"\"\"\n",
    "    Simple image differencing method\n",
    "    Computes absolute difference between images\n",
    "    \"\"\"\n",
    "    # Convert to grayscale for easier analysis\n",
    "    before_gray = cv2.cvtColor(before, cv2.COLOR_BGR2GRAY)\n",
    "    after_gray = cv2.cvtColor(after, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Compute absolute difference\n",
    "    diff = cv2.absdiff(after_gray, before_gray)\n",
    "    \n",
    "    return diff\n",
    "\n",
    "# Apply image differencing\n",
    "diff_image = image_differencing(before_proc, after_proc)\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "axes[0].imshow(cv2.cvtColor(before_proc, cv2.COLOR_BGR2RGB))\n",
    "axes[0].set_title('Before', fontsize=12, fontweight='bold')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(cv2.cvtColor(after_proc, cv2.COLOR_BGR2RGB))\n",
    "axes[1].set_title('After', fontsize=12, fontweight='bold')\n",
    "axes[1].axis('off')\n",
    "\n",
    "axes[2].imshow(diff_image, cmap='hot')\n",
    "axes[2].set_title('Difference Map', fontsize=12, fontweight='bold')\n",
    "axes[2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Difference image range: [{diff_image.min()}, {diff_image.max()}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c51787e",
   "metadata": {},
   "source": [
    "## 8. Thresholding for Change Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813b1a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_changes(diff_image, threshold=30, use_adaptive=False):\n",
    "    \"\"\"\n",
    "    Apply thresholding to create binary change mask\n",
    "    \"\"\"\n",
    "    if use_adaptive:\n",
    "        # Adaptive thresholding\n",
    "        change_mask = cv2.adaptiveThreshold(\n",
    "            diff_image, 255, \n",
    "            cv2.ADAPTIVE_THRESH_GAUSSIAN_C, \n",
    "            cv2.THRESH_BINARY, 11, 2\n",
    "        )\n",
    "    else:\n",
    "        # Simple thresholding\n",
    "        _, change_mask = cv2.threshold(diff_image, threshold, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # Apply morphological operations to reduce noise\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    change_mask = cv2.morphologyEx(change_mask, cv2.MORPH_OPEN, kernel)\n",
    "    change_mask = cv2.morphologyEx(change_mask, cv2.MORPH_CLOSE, kernel)\n",
    "    \n",
    "    return change_mask\n",
    "\n",
    "# Try different thresholds\n",
    "thresholds = [20, 30, 40]\n",
    "fig, axes = plt.subplots(1, len(thresholds) + 1, figsize=(16, 4))\n",
    "\n",
    "axes[0].imshow(diff_image, cmap='hot')\n",
    "axes[0].set_title('Difference Map', fontsize=11, fontweight='bold')\n",
    "axes[0].axis('off')\n",
    "\n",
    "for i, thresh in enumerate(thresholds):\n",
    "    mask = threshold_changes(diff_image, threshold=thresh)\n",
    "    axes[i+1].imshow(mask, cmap='gray')\n",
    "    axes[i+1].set_title(f'Threshold = {thresh}', fontsize=11, fontweight='bold')\n",
    "    axes[i+1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Use threshold of 30 for subsequent analysis\n",
    "change_mask = threshold_changes(diff_image, threshold=30)\n",
    "print(f\"Change mask created with threshold=30\")\n",
    "print(f\"Changed pixels: {np.sum(change_mask > 0)} ({100*np.sum(change_mask > 0)/change_mask.size:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4120dd1d",
   "metadata": {},
   "source": [
    "## 9. Change Vector Analysis (CVA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a658c9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_vector_analysis(before, after, threshold_percentile=90):\n",
    "    \"\"\"\n",
    "    Change Vector Analysis (CVA)\n",
    "    Computes magnitude and direction of spectral change\n",
    "    \"\"\"\n",
    "    # Normalize images\n",
    "    before_float = before.astype(np.float32)\n",
    "    after_float = after.astype(np.float32)\n",
    "    \n",
    "    # Compute change vector\n",
    "    change_vector = after_float - before_float\n",
    "    \n",
    "    # Compute magnitude of change\n",
    "    magnitude = np.sqrt(np.sum(change_vector**2, axis=2))\n",
    "    \n",
    "    # Compute direction (angle)\n",
    "    direction = np.arctan2(change_vector[:, :, 1], change_vector[:, :, 0])\n",
    "    \n",
    "    # Threshold by percentile\n",
    "    threshold_value = np.percentile(magnitude, threshold_percentile)\n",
    "    change_magnitude_mask = (magnitude > threshold_value).astype(np.uint8) * 255\n",
    "    \n",
    "    return magnitude, direction, change_magnitude_mask\n",
    "\n",
    "# Apply CVA\n",
    "magnitude, direction, cva_mask = change_vector_analysis(before_proc, after_proc, threshold_percentile=85)\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 12))\n",
    "\n",
    "axes[0, 0].imshow(cv2.cvtColor(before_proc, cv2.COLOR_BGR2RGB))\n",
    "axes[0, 0].set_title('Before Image', fontsize=12, fontweight='bold')\n",
    "axes[0, 0].axis('off')\n",
    "\n",
    "axes[0, 1].imshow(cv2.cvtColor(after_proc, cv2.COLOR_BGR2RGB))\n",
    "axes[0, 1].set_title('After Image', fontsize=12, fontweight='bold')\n",
    "axes[0, 1].axis('off')\n",
    "\n",
    "im1 = axes[1, 0].imshow(magnitude, cmap='jet')\n",
    "axes[1, 0].set_title('Change Magnitude (CVA)', fontsize=12, fontweight='bold')\n",
    "axes[1, 0].axis('off')\n",
    "plt.colorbar(im1, ax=axes[1, 0], fraction=0.046)\n",
    "\n",
    "axes[1, 1].imshow(cva_mask, cmap='gray')\n",
    "axes[1, 1].set_title('CVA Change Mask', fontsize=12, fontweight='bold')\n",
    "axes[1, 1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"CVA completed successfully!\")\n",
    "print(f\"Change magnitude range: [{magnitude.min():.2f}, {magnitude.max():.2f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a209722c",
   "metadata": {},
   "source": [
    "## 10. Deep Learning Approach - Simple Siamese Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be039f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "def create_simple_change_detection_model(input_shape=(256, 256, 3)):\n",
    "    \"\"\"\n",
    "    Create a simple CNN-based change detection model\n",
    "    Uses a Siamese-like architecture\n",
    "    \"\"\"\n",
    "    # Input layers\n",
    "    input_before = layers.Input(shape=input_shape, name='before_image')\n",
    "    input_after = layers.Input(shape=input_shape, name='after_image')\n",
    "    \n",
    "    # Shared feature extractor\n",
    "    def feature_extractor():\n",
    "        model = keras.Sequential([\n",
    "            layers.Conv2D(32, 3, activation='relu', padding='same'),\n",
    "            layers.MaxPooling2D(2),\n",
    "            layers.Conv2D(64, 3, activation='relu', padding='same'),\n",
    "            layers.MaxPooling2D(2),\n",
    "            layers.Conv2D(128, 3, activation='relu', padding='same'),\n",
    "            layers.MaxPooling2D(2),\n",
    "        ])\n",
    "        return model\n",
    "    \n",
    "    extractor = feature_extractor()\n",
    "    \n",
    "    # Extract features from both images\n",
    "    features_before = extractor(input_before)\n",
    "    features_after = extractor(input_after)\n",
    "    \n",
    "    # Concatenate features\n",
    "    combined = layers.Concatenate()([features_before, features_after])\n",
    "    \n",
    "    # Decoder for change detection\n",
    "    x = layers.Conv2D(128, 3, activation='relu', padding='same')(combined)\n",
    "    x = layers.UpSampling2D(2)(x)\n",
    "    x = layers.Conv2D(64, 3, activation='relu', padding='same')(x)\n",
    "    x = layers.UpSampling2D(2)(x)\n",
    "    x = layers.Conv2D(32, 3, activation='relu', padding='same')(x)\n",
    "    x = layers.UpSampling2D(2)(x)\n",
    "    \n",
    "    # Output change map\n",
    "    output = layers.Conv2D(1, 1, activation='sigmoid', padding='same', name='change_map')(x)\n",
    "    \n",
    "    # Create model\n",
    "    model = keras.Model(inputs=[input_before, input_after], outputs=output)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create model\n",
    "print(\"Creating deep learning model...\")\n",
    "model = create_simple_change_detection_model(input_shape=(256, 256, 3))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "print(\"Model created successfully!\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad62924a",
   "metadata": {},
   "source": [
    "## 11. Deep Learning Change Detection (Inference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6770c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: This is inference with an untrained model (for demonstration)\n",
    "# In practice, you would train this model on labeled change detection data\n",
    "\n",
    "def predict_changes_dl(model, before, after):\n",
    "    \"\"\"\n",
    "    Predict changes using deep learning model\n",
    "    \"\"\"\n",
    "    # Prepare inputs\n",
    "    before_input = np.expand_dims(before_norm, axis=0)\n",
    "    after_input = np.expand_dims(after_norm, axis=0)\n",
    "    \n",
    "    # Predict\n",
    "    change_pred = model.predict([before_input, after_input], verbose=0)\n",
    "    \n",
    "    # Remove batch dimension and squeeze\n",
    "    change_pred = np.squeeze(change_pred)\n",
    "    \n",
    "    return change_pred\n",
    "\n",
    "# Run inference\n",
    "print(\"Running deep learning inference...\")\n",
    "dl_change_map = predict_changes_dl(model, before_proc, after_proc)\n",
    "\n",
    "# Threshold the prediction\n",
    "dl_change_mask = (dl_change_map > 0.5).astype(np.uint8) * 255\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 12))\n",
    "\n",
    "axes[0, 0].imshow(cv2.cvtColor(before_proc, cv2.COLOR_BGR2RGB))\n",
    "axes[0, 0].set_title('Before Image', fontsize=12, fontweight='bold')\n",
    "axes[0, 0].axis('off')\n",
    "\n",
    "axes[0, 1].imshow(cv2.cvtColor(after_proc, cv2.COLOR_BGR2RGB))\n",
    "axes[0, 1].set_title('After Image', fontsize=12, fontweight='bold')\n",
    "axes[0, 1].axis('off')\n",
    "\n",
    "im = axes[1, 0].imshow(dl_change_map, cmap='hot', vmin=0, vmax=1)\n",
    "axes[1, 0].set_title('DL Change Probability', fontsize=12, fontweight='bold')\n",
    "axes[1, 0].axis('off')\n",
    "plt.colorbar(im, ax=axes[1, 0], fraction=0.046)\n",
    "\n",
    "axes[1, 1].imshow(dl_change_mask, cmap='gray')\n",
    "axes[1, 1].set_title('DL Change Mask', fontsize=12, fontweight='bold')\n",
    "axes[1, 1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Note: This uses an untrained model for demonstration.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0165f4ed",
   "metadata": {},
   "source": [
    "## 12. Visualize Detected Changes with Overlay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a51e4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlay_changes(original_image, change_mask, color=(255, 0, 0), alpha=0.4):\n",
    "    \"\"\"\n",
    "    Overlay change mask on original image with transparency\n",
    "    \"\"\"\n",
    "    # Create overlay\n",
    "    overlay = original_image.copy()\n",
    "    \n",
    "    # Create red mask for changes\n",
    "    red_mask = np.zeros_like(original_image)\n",
    "    red_mask[change_mask > 0] = color\n",
    "    \n",
    "    # Blend\n",
    "    result = cv2.addWeighted(overlay, 1-alpha, red_mask, alpha, 0)\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Create overlays for different methods\n",
    "overlay_threshold = overlay_changes(after_proc, change_mask, color=(255, 0, 0), alpha=0.5)\n",
    "overlay_cva = overlay_changes(after_proc, cva_mask, color=(0, 255, 255), alpha=0.5)\n",
    "overlay_dl = overlay_changes(after_proc, dl_change_mask, color=(0, 255, 0), alpha=0.5)\n",
    "\n",
    "# Visualize all methods\n",
    "fig, axes = plt.subplots(2, 3, figsize=(16, 10))\n",
    "\n",
    "axes[0, 0].imshow(cv2.cvtColor(before_proc, cv2.COLOR_BGR2RGB))\n",
    "axes[0, 0].set_title('Before Image', fontsize=12, fontweight='bold')\n",
    "axes[0, 0].axis('off')\n",
    "\n",
    "axes[0, 1].imshow(cv2.cvtColor(after_proc, cv2.COLOR_BGR2RGB))\n",
    "axes[0, 1].set_title('After Image', fontsize=12, fontweight='bold')\n",
    "axes[0, 1].axis('off')\n",
    "\n",
    "axes[0, 2].imshow(diff_image, cmap='hot')\n",
    "axes[0, 2].set_title('Difference Map', fontsize=12, fontweight='bold')\n",
    "axes[0, 2].axis('off')\n",
    "\n",
    "axes[1, 0].imshow(cv2.cvtColor(overlay_threshold, cv2.COLOR_BGR2RGB))\n",
    "axes[1, 0].set_title('Threshold Method (Red)', fontsize=12, fontweight='bold')\n",
    "axes[1, 0].axis('off')\n",
    "\n",
    "axes[1, 1].imshow(cv2.cvtColor(overlay_cva, cv2.COLOR_BGR2RGB))\n",
    "axes[1, 1].set_title('CVA Method (Cyan)', fontsize=12, fontweight='bold')\n",
    "axes[1, 1].axis('off')\n",
    "\n",
    "axes[1, 2].imshow(cv2.cvtColor(overlay_dl, cv2.COLOR_BGR2RGB))\n",
    "axes[1, 2].set_title('Deep Learning Method (Green)', fontsize=12, fontweight='bold')\n",
    "axes[1, 2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Change overlays created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5bbf8d",
   "metadata": {},
   "source": [
    "## 13. Calculate Change Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83cbe32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_change_statistics(change_mask, image_shape):\n",
    "    \"\"\"\n",
    "    Calculate statistics about detected changes\n",
    "    \"\"\"\n",
    "    total_pixels = change_mask.size\n",
    "    changed_pixels = np.sum(change_mask > 0)\n",
    "    unchanged_pixels = total_pixels - changed_pixels\n",
    "    \n",
    "    change_percentage = (changed_pixels / total_pixels) * 100\n",
    "    \n",
    "    # Find contours (connected change regions)\n",
    "    contours, _ = cv2.findContours(change_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    num_change_regions = len(contours)\n",
    "    \n",
    "    # Calculate area of largest change\n",
    "    if contours:\n",
    "        largest_change_area = max([cv2.contourArea(c) for c in contours])\n",
    "        average_change_area = changed_pixels / num_change_regions if num_change_regions > 0 else 0\n",
    "    else:\n",
    "        largest_change_area = 0\n",
    "        average_change_area = 0\n",
    "    \n",
    "    stats = {\n",
    "        'total_pixels': total_pixels,\n",
    "        'changed_pixels': changed_pixels,\n",
    "        'unchanged_pixels': unchanged_pixels,\n",
    "        'change_percentage': change_percentage,\n",
    "        'num_change_regions': num_change_regions,\n",
    "        'largest_change_area': largest_change_area,\n",
    "        'average_change_area': average_change_area\n",
    "    }\n",
    "    \n",
    "    return stats\n",
    "\n",
    "# Calculate statistics for all methods\n",
    "stats_threshold = calculate_change_statistics(change_mask, before_proc.shape)\n",
    "stats_cva = calculate_change_statistics(cva_mask, before_proc.shape)\n",
    "stats_dl = calculate_change_statistics(dl_change_mask, before_proc.shape)\n",
    "\n",
    "# Display results\n",
    "print(\"=\" * 70)\n",
    "print(\"CHANGE DETECTION STATISTICS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nüìä THRESHOLD METHOD:\")\n",
    "print(f\"  ‚Ä¢ Total Pixels: {stats_threshold['total_pixels']:,}\")\n",
    "print(f\"  ‚Ä¢ Changed Pixels: {stats_threshold['changed_pixels']:,}\")\n",
    "print(f\"  ‚Ä¢ Change Percentage: {stats_threshold['change_percentage']:.2f}%\")\n",
    "print(f\"  ‚Ä¢ Number of Change Regions: {stats_threshold['num_change_regions']}\")\n",
    "print(f\"  ‚Ä¢ Largest Change Area: {stats_threshold['largest_change_area']:.0f} pixels\")\n",
    "\n",
    "print(\"\\nüìä CHANGE VECTOR ANALYSIS (CVA):\")\n",
    "print(f\"  ‚Ä¢ Total Pixels: {stats_cva['total_pixels']:,}\")\n",
    "print(f\"  ‚Ä¢ Changed Pixels: {stats_cva['changed_pixels']:,}\")\n",
    "print(f\"  ‚Ä¢ Change Percentage: {stats_cva['change_percentage']:.2f}%\")\n",
    "print(f\"  ‚Ä¢ Number of Change Regions: {stats_cva['num_change_regions']}\")\n",
    "print(f\"  ‚Ä¢ Largest Change Area: {stats_cva['largest_change_area']:.0f} pixels\")\n",
    "\n",
    "print(\"\\nüìä DEEP LEARNING METHOD:\")\n",
    "print(f\"  ‚Ä¢ Total Pixels: {stats_dl['total_pixels']:,}\")\n",
    "print(f\"  ‚Ä¢ Changed Pixels: {stats_dl['changed_pixels']:,}\")\n",
    "print(f\"  ‚Ä¢ Change Percentage: {stats_dl['change_percentage']:.2f}%\")\n",
    "print(f\"  ‚Ä¢ Number of Change Regions: {stats_dl['num_change_regions']}\")\n",
    "print(f\"  ‚Ä¢ Largest Change Area: {stats_dl['largest_change_area']:.0f} pixels\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8a3dbb",
   "metadata": {},
   "source": [
    "## 13.5. Advanced Metrics (Kappa Coefficient, F1 Score, Precision, Recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65fa4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_advanced_metrics(predicted_mask, ground_truth_mask):\n",
    "    \"\"\"\n",
    "    Calculate advanced metrics for change detection evaluation\n",
    "    \n",
    "    Metrics included:\n",
    "    - Kappa Coefficient (Cohen's Kappa)\n",
    "    - F1 Score\n",
    "    - Precision\n",
    "    - Recall\n",
    "    - Overall Accuracy\n",
    "    - Producer's Accuracy (for both classes)\n",
    "    - User's Accuracy (for both classes)\n",
    "    - False Positive Rate\n",
    "    - False Negative Rate\n",
    "    \"\"\"\n",
    "    # Flatten masks to 1D arrays\n",
    "    pred = (predicted_mask > 0).flatten().astype(int)\n",
    "    gt = (ground_truth_mask > 0).flatten().astype(int)\n",
    "    \n",
    "    # Calculate confusion matrix elements\n",
    "    TP = np.sum((pred == 1) & (gt == 1))  # True Positives\n",
    "    TN = np.sum((pred == 0) & (gt == 0))  # True Negatives\n",
    "    FP = np.sum((pred == 1) & (gt == 0))  # False Positives\n",
    "    FN = np.sum((pred == 0) & (gt == 1))  # False Negatives\n",
    "    \n",
    "    # Overall Accuracy\n",
    "    overall_accuracy = (TP + TN) / (TP + TN + FP + FN) if (TP + TN + FP + FN) > 0 else 0\n",
    "    \n",
    "    # Precision (User's Accuracy for Changed class)\n",
    "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "    \n",
    "    # Recall (Producer's Accuracy for Changed class / Sensitivity)\n",
    "    recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "    \n",
    "    # F1 Score (Harmonic mean of Precision and Recall)\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    # Kappa Coefficient (Cohen's Kappa)\n",
    "    po = overall_accuracy  # Observed agreement\n",
    "    \n",
    "    # Expected agreement\n",
    "    total = TP + TN + FP + FN\n",
    "    pred_positive = TP + FP\n",
    "    pred_negative = TN + FN\n",
    "    actual_positive = TP + FN\n",
    "    actual_negative = TN + FP\n",
    "    \n",
    "    pe = ((pred_positive * actual_positive) + (pred_negative * actual_negative)) / (total ** 2) if total > 0 else 0\n",
    "    \n",
    "    # Kappa coefficient\n",
    "    kappa = (po - pe) / (1 - pe) if (1 - pe) != 0 else 0\n",
    "    \n",
    "    # Producer's Accuracy (for both classes)\n",
    "    producer_acc_changed = recall  # Same as recall\n",
    "    producer_acc_unchanged = TN / (TN + FP) if (TN + FP) > 0 else 0\n",
    "    \n",
    "    # User's Accuracy (for both classes)\n",
    "    user_acc_changed = precision  # Same as precision\n",
    "    user_acc_unchanged = TN / (TN + FN) if (TN + FN) > 0 else 0\n",
    "    \n",
    "    # False Positive Rate (Fall-out)\n",
    "    fpr = FP / (FP + TN) if (FP + TN) > 0 else 0\n",
    "    \n",
    "    # False Negative Rate (Miss rate)\n",
    "    fnr = FN / (FN + TP) if (FN + TP) > 0 else 0\n",
    "    \n",
    "    metrics = {\n",
    "        'confusion_matrix': {\n",
    "            'TP': int(TP),\n",
    "            'TN': int(TN),\n",
    "            'FP': int(FP),\n",
    "            'FN': int(FN)\n",
    "        },\n",
    "        'kappa_coefficient': kappa,\n",
    "        'f1_score': f1_score,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'overall_accuracy': overall_accuracy,\n",
    "        'producer_accuracy_changed': producer_acc_changed,\n",
    "        'producer_accuracy_unchanged': producer_acc_unchanged,\n",
    "        'user_accuracy_changed': user_acc_changed,\n",
    "        'user_accuracy_unchanged': user_acc_unchanged,\n",
    "        'false_positive_rate': fpr,\n",
    "        'false_negative_rate': fnr\n",
    "    }\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Create a synthetic ground truth for demonstration\n",
    "# In practice, you would have actual ground truth labels\n",
    "ground_truth = np.zeros_like(change_mask)\n",
    "ground_truth[100:180, 100:180] = 255  # Simulated true change area\n",
    "ground_truth[150:200, 150:200] = 255  # Another change area\n",
    "\n",
    "# Calculate advanced metrics for all methods\n",
    "metrics_threshold = calculate_advanced_metrics(change_mask, ground_truth)\n",
    "metrics_cva = calculate_advanced_metrics(cva_mask, ground_truth)\n",
    "metrics_dl = calculate_advanced_metrics(dl_change_mask, ground_truth)\n",
    "\n",
    "# Display results\n",
    "print(\"=\" * 80)\n",
    "print(\"ADVANCED CHANGE DETECTION METRICS\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\n‚ö†Ô∏è  Note: Using synthetic ground truth for demonstration.\")\n",
    "print(\"    Replace 'ground_truth' with your actual labeled data.\\n\")\n",
    "\n",
    "def print_metrics(metrics, method_name):\n",
    "    print(f\"\\nüìä {method_name}:\")\n",
    "    print(f\"  Confusion Matrix:\")\n",
    "    print(f\"    ‚Ä¢ True Positives (TP):  {metrics['confusion_matrix']['TP']:,}\")\n",
    "    print(f\"    ‚Ä¢ True Negatives (TN):  {metrics['confusion_matrix']['TN']:,}\")\n",
    "    print(f\"    ‚Ä¢ False Positives (FP): {metrics['confusion_matrix']['FP']:,}\")\n",
    "    print(f\"    ‚Ä¢ False Negatives (FN): {metrics['confusion_matrix']['FN']:,}\")\n",
    "    print(f\"  \")\n",
    "    print(f\"  Accuracy Metrics:\")\n",
    "    print(f\"    ‚Ä¢ Overall Accuracy:     {metrics['overall_accuracy']:.4f} ({metrics['overall_accuracy']*100:.2f}%)\")\n",
    "    print(f\"    ‚Ä¢ Kappa Coefficient:    {metrics['kappa_coefficient']:.4f}\")\n",
    "    print(f\"  \")\n",
    "    print(f\"  Performance Metrics:\")\n",
    "    print(f\"    ‚Ä¢ F1 Score:             {metrics['f1_score']:.4f}\")\n",
    "    print(f\"    ‚Ä¢ Precision:            {metrics['precision']:.4f} ({metrics['precision']*100:.2f}%)\")\n",
    "    print(f\"    ‚Ä¢ Recall (Sensitivity): {metrics['recall']:.4f} ({metrics['recall']*100:.2f}%)\")\n",
    "    print(f\"  \")\n",
    "    print(f\"  Error Rates:\")\n",
    "    print(f\"    ‚Ä¢ False Positive Rate:  {metrics['false_positive_rate']:.4f} ({metrics['false_positive_rate']*100:.2f}%)\")\n",
    "    print(f\"    ‚Ä¢ False Negative Rate:  {metrics['false_negative_rate']:.4f} ({metrics['false_negative_rate']*100:.2f}%)\")\n",
    "    print(f\"  \")\n",
    "    print(f\"  Class-wise Accuracies:\")\n",
    "    print(f\"    ‚Ä¢ Producer's Acc (Changed):   {metrics['producer_accuracy_changed']:.4f}\")\n",
    "    print(f\"    ‚Ä¢ Producer's Acc (Unchanged): {metrics['producer_accuracy_unchanged']:.4f}\")\n",
    "    print(f\"    ‚Ä¢ User's Acc (Changed):       {metrics['user_accuracy_changed']:.4f}\")\n",
    "    print(f\"    ‚Ä¢ User's Acc (Unchanged):     {metrics['user_accuracy_unchanged']:.4f}\")\n",
    "\n",
    "print_metrics(metrics_threshold, \"THRESHOLD METHOD\")\n",
    "print_metrics(metrics_cva, \"CHANGE VECTOR ANALYSIS (CVA)\")\n",
    "print_metrics(metrics_dl, \"DEEP LEARNING METHOD\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "\n",
    "# Visualize confusion matrices\n",
    "fig, axes = plt.subplots(1, 4, figsize=(18, 4))\n",
    "\n",
    "# Ground truth\n",
    "axes[0].imshow(ground_truth, cmap='gray')\n",
    "axes[0].set_title('Ground Truth\\n(Synthetic)', fontsize=11, fontweight='bold')\n",
    "axes[0].axis('off')\n",
    "\n",
    "# Threshold method\n",
    "axes[1].imshow(change_mask, cmap='gray')\n",
    "axes[1].set_title(f'Threshold Method\\nKappa: {metrics_threshold[\"kappa_coefficient\"]:.3f} | F1: {metrics_threshold[\"f1_score\"]:.3f}', \n",
    "                 fontsize=10, fontweight='bold')\n",
    "axes[1].axis('off')\n",
    "\n",
    "# CVA method\n",
    "axes[2].imshow(cva_mask, cmap='gray')\n",
    "axes[2].set_title(f'CVA Method\\nKappa: {metrics_cva[\"kappa_coefficient\"]:.3f} | F1: {metrics_cva[\"f1_score\"]:.3f}', \n",
    "                 fontsize=10, fontweight='bold')\n",
    "axes[2].axis('off')\n",
    "\n",
    "# DL method\n",
    "axes[3].imshow(dl_change_mask, cmap='gray')\n",
    "axes[3].set_title(f'Deep Learning\\nKappa: {metrics_dl[\"kappa_coefficient\"]:.3f} | F1: {metrics_dl[\"f1_score\"]:.3f}', \n",
    "                 fontsize=10, fontweight='bold')\n",
    "axes[3].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3067e629",
   "metadata": {},
   "source": [
    "## 14. Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffb2a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory\n",
    "output_dir = os.path.join(working_dir, 'results')\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Save change masks\n",
    "cv2.imwrite(os.path.join(output_dir, 'before_image.png'), before_proc)\n",
    "cv2.imwrite(os.path.join(output_dir, 'after_image.png'), after_proc)\n",
    "cv2.imwrite(os.path.join(output_dir, 'difference_map.png'), diff_image)\n",
    "cv2.imwrite(os.path.join(output_dir, 'threshold_change_mask.png'), change_mask)\n",
    "cv2.imwrite(os.path.join(output_dir, 'cva_change_mask.png'), cva_mask)\n",
    "cv2.imwrite(os.path.join(output_dir, 'dl_change_mask.png'), dl_change_mask)\n",
    "\n",
    "# Save overlays\n",
    "cv2.imwrite(os.path.join(output_dir, 'threshold_overlay.png'), overlay_threshold)\n",
    "cv2.imwrite(os.path.join(output_dir, 'cva_overlay.png'), overlay_cva)\n",
    "cv2.imwrite(os.path.join(output_dir, 'dl_overlay.png'), overlay_dl)\n",
    "\n",
    "# Save statistics to text file\n",
    "stats_file = os.path.join(output_dir, 'change_statistics.txt')\n",
    "with open(stats_file, 'w') as f:\n",
    "    f.write(\"SATELLITE CHANGE DETECTION RESULTS\\n\")\n",
    "    f.write(\"=\" * 80 + \"\\n\\n\")\n",
    "    \n",
    "    f.write(\"BASIC STATISTICS:\\n\")\n",
    "    f.write(\"-\" * 80 + \"\\n\\n\")\n",
    "    \n",
    "    f.write(\"THRESHOLD METHOD:\\n\")\n",
    "    for key, value in stats_threshold.items():\n",
    "        f.write(f\"  {key}: {value}\\n\")\n",
    "    \n",
    "    f.write(\"\\nCHANGE VECTOR ANALYSIS (CVA):\\n\")\n",
    "    for key, value in stats_cva.items():\n",
    "        f.write(f\"  {key}: {value}\\n\")\n",
    "    \n",
    "    f.write(\"\\nDEEP LEARNING METHOD:\\n\")\n",
    "    for key, value in stats_dl.items():\n",
    "        f.write(f\"  {key}: {value}\\n\")\n",
    "    \n",
    "    # Add advanced metrics\n",
    "    f.write(\"\\n\\n\" + \"=\" * 80 + \"\\n\")\n",
    "    f.write(\"ADVANCED METRICS (Kappa, F1, Precision, Recall)\\n\")\n",
    "    f.write(\"=\" * 80 + \"\\n\\n\")\n",
    "    \n",
    "    def write_metrics(f, metrics, method_name):\n",
    "        f.write(f\"{method_name}:\\n\")\n",
    "        f.write(f\"  Confusion Matrix:\\n\")\n",
    "        f.write(f\"    TP: {metrics['confusion_matrix']['TP']:,}\\n\")\n",
    "        f.write(f\"    TN: {metrics['confusion_matrix']['TN']:,}\\n\")\n",
    "        f.write(f\"    FP: {metrics['confusion_matrix']['FP']:,}\\n\")\n",
    "        f.write(f\"    FN: {metrics['confusion_matrix']['FN']:,}\\n\")\n",
    "        f.write(f\"  Overall Accuracy: {metrics['overall_accuracy']:.4f}\\n\")\n",
    "        f.write(f\"  Kappa Coefficient: {metrics['kappa_coefficient']:.4f}\\n\")\n",
    "        f.write(f\"  F1 Score: {metrics['f1_score']:.4f}\\n\")\n",
    "        f.write(f\"  Precision: {metrics['precision']:.4f}\\n\")\n",
    "        f.write(f\"  Recall: {metrics['recall']:.4f}\\n\")\n",
    "        f.write(f\"  False Positive Rate: {metrics['false_positive_rate']:.4f}\\n\")\n",
    "        f.write(f\"  False Negative Rate: {metrics['false_negative_rate']:.4f}\\n\\n\")\n",
    "    \n",
    "    write_metrics(f, metrics_threshold, \"THRESHOLD METHOD\")\n",
    "    write_metrics(f, metrics_cva, \"CHANGE VECTOR ANALYSIS (CVA)\")\n",
    "    write_metrics(f, metrics_dl, \"DEEP LEARNING METHOD\")\n",
    "\n",
    "# Save ground truth\n",
    "cv2.imwrite(os.path.join(output_dir, 'ground_truth.png'), ground_truth)\n",
    "\n",
    "print(f\"\\nSaved files:\")\n",
    "print(\"  ‚Ä¢ before_image.png\")\n",
    "print(\"  ‚Ä¢ after_image.png\")\n",
    "print(\"  ‚Ä¢ difference_map.png\")\n",
    "print(\"  ‚Ä¢ ground_truth.png\")\n",
    "print(\"  ‚Ä¢ threshold_change_mask.png\")\n",
    "print(\"  ‚Ä¢ cva_change_mask.png\")\n",
    "print(\"  ‚Ä¢ dl_change_mask.png\")\n",
    "print(\"  ‚Ä¢ threshold_overlay.png\")\n",
    "print(\"  ‚Ä¢ cva_overlay.png\")\n",
    "print(\"  ‚Ä¢ dl_overlay.png\")\n",
    "print(\"  ‚Ä¢ change_statistics.txt (includes advanced metrics)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbae7d50",
   "metadata": {},
   "source": [
    "## üöÄ How to Use This Notebook\n",
    "\n",
    "### For Your Own Satellite Images:\n",
    "\n",
    "1. **Replace the sample image creation** in Section 4 with your own image loading code:\n",
    "```python\n",
    "# Load your own satellite images\n",
    "before_img = cv2.imread('path/to/your/before_image.tif')\n",
    "after_img = cv2.imread('path/to/your/after_image.tif')\n",
    "```\n",
    "\n",
    "2. **For GeoTIFF files**, use rasterio:\n",
    "```python\n",
    "import rasterio\n",
    "with rasterio.open('your_satellite_image.tif') as src:\n",
    "    image = src.read()  # Read all bands\n",
    "    image = np.transpose(image, (1, 2, 0))  # Rearrange to (H, W, C)\n",
    "```\n",
    "\n",
    "3. **Adjust parameters** based on your data:\n",
    "   - Threshold values in Section 8\n",
    "   - CVA percentile in Section 9\n",
    "   - Model architecture in Section 10 (if training)\n",
    "\n",
    "### Training the Deep Learning Model:\n",
    "\n",
    "To train the model on your own labeled data:\n",
    "```python\n",
    "# Prepare your training data\n",
    "X_train_before = [...]  # List of before images\n",
    "X_train_after = [...]   # List of after images\n",
    "y_train = [...]         # List of change masks (ground truth)\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "    [X_train_before, X_train_after],\n",
    "    y_train,\n",
    "    epochs=50,\n",
    "    batch_size=8,\n",
    "    validation_split=0.2\n",
    ")\n",
    "```\n",
    "\n",
    "### Key Features:\n",
    "‚úÖ Multiple change detection methods  \n",
    "‚úÖ Google Colab compatible  \n",
    "‚úÖ Visualization and statistics  \n",
    "‚úÖ Export results in multiple formats  \n",
    "‚úÖ Easy to customize for your data"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
